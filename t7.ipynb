{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "使用flyai进行文本分类,使用的模型是bert模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载参数和配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tensorflow as tf\n",
    "from flyai.dataset import Dataset\n",
    "from model import Model\n",
    "from path import MODEL_PATH, LOG_PATH\n",
    "from data_helper import *\n",
    "import bert.modeling as modeling\n",
    "\n",
    "\n",
    "# 超参\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=10, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=16, type=int, help=\"batch size\")\n",
    "args = parser.parse_args()\n",
    "# 数据获取辅助类\n",
    "dataset = Dataset(epochs=args.EPOCHS, batch=args.BATCH)\n",
    "# 模型操作辅助类\n",
    "modelpp = Model(dataset)\n",
    "\n",
    "path = modelpp.get_remote_date(\"https://www.flyai.com/m/multi_cased_L-12_H-768_A-12.zip\")\n",
    "print(path)\n",
    "'''\n",
    "使用tensorflow实现自己的算法\n",
    "'''\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.0006     # 学习率\n",
    "num_labels = 3  #类别数\n",
    "is_training = False\n",
    "\n",
    "# ——————————————————配置文件——————————————————\n",
    "# data_root = os.path.splitext(path)[0]\n",
    "data_root = r'multi_cased_L-12_H-768_A-12\\multi_cased_L-12_H-768_A-12'\n",
    "bert_config_file = os.path.join(data_root, 'bert_config.json')\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "init_checkpoint = os.path.join(data_root, 'bert_model.ckpt')\n",
    "bert_vocab_file = os.path.join(data_root, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化bert模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——————————————————导入数据——————————————————————\n",
    "input_ids = tf.placeholder(tf.int32, shape=[None, None], name='input_ids')\n",
    "input_mask = tf.placeholder(tf.int32, shape=[None, None], name='input_masks')\n",
    "segment_ids = tf.placeholder(tf.int32, shape=[None, None], name='segment_ids')\n",
    "labels = tf.placeholder(tf.int32, shape=[None, ], name='labels')\n",
    "\n",
    "# ——————————————————定义神经网络变量——————————————————\n",
    "# 初始化BERT\n",
    "model = modeling.BertModel(\n",
    "                        config=bert_config,\n",
    "                        is_training=is_training,\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        token_type_ids=segment_ids,\n",
    "                        use_one_hot_embeddings=False)\n",
    "\n",
    "# 加载bert模型\n",
    "tvars = tf.trainable_variables()\n",
    "(assignment, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment)\n",
    "# 获取最后一层。\n",
    "# 输出[batch_size, seq_length, embedding_size] 如果做seq2seq 或者ner用这个\n",
    "# output_layer_seq = model.get_sequence_output()  # 这个获取每个token的output\n",
    "# 这个获取句子的output\n",
    "output_layer = tf.identity(model.get_pooled_output(), name='output_layer_pooled')\n",
    "\n",
    "# 根据输出的句向量计算维度\n",
    "hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "# 构建W 和 b\n",
    "output_weights = tf.get_variable(\n",
    "                \"output_weights\", [hidden_size, num_labels],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "output_bias = tf.get_variable(\n",
    "                \"output_bias\", [num_labels], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行预测并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    # 准确率\n",
    "    correct_pred = tf.equal(labels, tf.cast(pred, tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='acc')\n",
    "\n",
    "with tf.name_scope(\"optimize\"):\n",
    "    # 将label进行onehot转化\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "    # 构建损失函数\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "    # 优化器\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"summary\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"acc\", accuracy)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter(LOG_PATH, sess.graph)\n",
    "\n",
    "    print('dataset.get_step:', dataset.get_step())\n",
    "    for step in range(dataset.get_step()):\n",
    "        x_train, y_train, _, _ = dataset.next_batch(args.BATCH)\n",
    "        x_input_ids = x_train[0]\n",
    "        x_input_mask = x_train[1]\n",
    "        x_segment_ids = x_train[2]\n",
    "\n",
    "        fetches = [train_op, loss, accuracy]\n",
    "        feed_dict = {input_ids: x_input_ids, input_mask: x_input_mask, segment_ids: x_segment_ids, labels: y_train}\n",
    "        _, loss_, acc_ = sess.run(fetches, feed_dict=feed_dict)\n",
    "\n",
    "        summary = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "        cur_step = str(step + 1) + \"/\" + str(dataset.get_step())\n",
    "        print('The Current step per total: {} | The Current loss: {} | The current acc: {}'.\n",
    "              format(cur_step, loss_, acc_))\n",
    "        if step % 50 == 0:\n",
    "            modelpp.save_model(sess, MODEL_PATH, overwrite=True)\n",
    "    modelpp.save_model(sess, MODEL_PATH, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
