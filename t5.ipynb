{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "使用textRNN进行文本分类，还是使用flyai的框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=50, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=64, type=int, help=\"batch size\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "'''\n",
    "flyai库中的提供的数据处理方法\n",
    "传入整个数据训练多少轮，每批次批大小\n",
    "'''\n",
    "dataset = Dataset(epochs=args.EPOCHS, batch=args.BATCH)\n",
    "model = Model(dataset)\n",
    "\n",
    "# 超参\n",
    "vocab_size = 20655      # 总词汇量\n",
    "embedding_dim = 100      # 嵌入层大小\n",
    "hidden_dim = 100        # Dense层大小\n",
    "max_seq_len = 34        # 最大句长\n",
    "num_filters = 256       # 卷积核数目\n",
    "kernel_size = 5         # 卷积核尺寸\n",
    "learning_rate = 1e-3    # 学习率\n",
    "numclass = 3            # 类别数\n",
    "num_layers = 2\n",
    "\n",
    "\n",
    "# 传值空间\n",
    "input_x = tf.placeholder(tf.int32, shape=[None, max_seq_len], name='input_x')\n",
    "input_y = tf.placeholder(tf.int32, shape=[None], name='input_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope(\"textrnn\"):\n",
    "    # CNN layer\n",
    "    x_input_embedded = tf.nn.embedding_lookup(input_embedding, input_x)\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(hidden_dim)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, output_keep_prob=keep_prob)\n",
    "    cells = [cell for _ in range(num_layers)]\n",
    "    Cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "    output, _ = tf.nn.dynamic_rnn(cell=Cell, inputs=x_input_embedded,\n",
    "                                  dtype=tf.float32)\n",
    "    output = tf.reduce_sum(output, axis=1)\n",
    "    dropout = tf.nn.dropout(output, keep_prob=keep_prob)\n",
    "    W = tf.Variable(tf.truncated_normal([hidden_dim, numclass], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[numclass]))\n",
    "    logits = tf.matmul(dropout, W) + b\n",
    "    # conv = tf.layers.conv1d(x_input_embedded, num_filters, kernel_size, name='conv')\n",
    "    # # global max pooling layer\n",
    "    # pooling = tf.reduce_max(conv, reduction_indices=[1])\n",
    "\n",
    "\n",
    "with tf.name_scope(\"score\"):\n",
    "    # 全连接层，后面接dropout以及relu激活\n",
    "\n",
    "\n",
    "\n",
    "    y_pred_cls = tf.argmax(tf.nn.softmax(logits), 1, name='y_pred')  # 预测类别\n",
    "\n",
    "with tf.name_scope(\"optimize\"):\n",
    "    # 将label进行onehot转化\n",
    "    one_hot_labels = tf.one_hot(input_y, depth=numclass, dtype=tf.float32)\n",
    "    # 损失函数，交叉熵\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_labels)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # 优化器\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    # 准确率\n",
    "    correct_pred = tf.equal(tf.argmax(one_hot_labels, 1), y_pred_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='acc')\n",
    "\n",
    "with tf.name_scope(\"summary\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "best_score = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter(LOG_PATH, sess.graph)\n",
    "\n",
    "    # dataset.get_step() 获取数据的总迭代次数\n",
    "    for step in range(dataset.get_step()):\n",
    "        x_train, y_train = dataset.next_train_batch()\n",
    "        # x_val, y_val = dataset.next_validation_batch()\n",
    "\n",
    "        fetches = [loss, accuracy, train_op]\n",
    "        feed_dict = {input_x: x_train, input_y: y_train, keep_prob: 0.9}\n",
    "        loss_, accuracy_, _ = sess.run(fetches, feed_dict=feed_dict)\n",
    "\n",
    "        summary = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        cur_step = str(step + 1) + \"/\" + str(dataset.get_step())\n",
    "        print('The Current step per total: {} | The Current loss: {} | The Current ACC: {}'.\n",
    "              format(cur_step, loss_, accuracy_))\n",
    "        if step % 100 == 0:\n",
    "            model.save_model(sess, MODEL_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出结果不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Current step per total: 90/100 | The Current loss: 2.2351731132630448e-08 | The Current ACC: 1.0\n",
    "The Current step per total: 91/100 | The Current loss: 7.778337021591142e-06 | The Current ACC: 1.0\n",
    "The Current step per total: 92/100 | The Current loss: 7.450578820566989e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 93/100 | The Current loss: 1.8626450382086546e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 94/100 | The Current loss: 5.587934559514451e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 95/100 | The Current loss: 1.1175868230850483e-08 | The Current ACC: 1.0\n",
    "The Current step per total: 96/100 | The Current loss: 1.8626450382086546e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 97/100 | The Current loss: 7.4505797087454084e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 98/100 | The Current loss: 3.7252898543727042e-09 | The Current ACC: 1.0\n",
    "The Current step per total: 99/100 | The Current loss: 3.0174564358276257e-07 | The Current ACC: 1.0\n",
    "The Current step per total: 100/100 | The Current loss: 5.587935003603661e-09 | The Current ACC: 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用RCNN进行文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=10, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=64, type=int, help=\"batch size\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "'''\n",
    "flyai库中的提供的数据处理方法\n",
    "传入整个数据训练多少轮，每批次批大小\n",
    "'''\n",
    "dataset = Dataset(epochs=args.EPOCHS, batch=args.BATCH)\n",
    "model = Model(dataset)\n",
    "\n",
    "# 超参\n",
    "vocab_size = 20655      # 总词汇量\n",
    "embedding_dim = 300      # 嵌入层大小\n",
    "hidden_dim = 512        # Dense层大小\n",
    "max_seq_len = 34        # 最大句长\n",
    "num_filters = 256       # 卷积核数目\n",
    "kernel_size = 5         # 卷积核尺寸\n",
    "learning_rate = 1e-3    # 学习率\n",
    "numclass = 3            # 类别数\n",
    "text_hidden_size = 512\n",
    "\n",
    "# 传值空间\n",
    "input_x = tf.placeholder(tf.int32, shape=[None, max_seq_len], name='input_x')\n",
    "input_y = tf.placeholder(tf.int32, shape=[None], name='input_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "# define embedding layer\n",
    "with tf.variable_scope('embedding'):\n",
    "    # 标准正态分布初始化\n",
    "    input_embedding = tf.Variable(\n",
    "        tf.truncated_normal(shape=[vocab_size, embedding_dim], stddev=0.1), name='encoder_embedding')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"rcnn\"):\n",
    "    # CNN layer\n",
    "    x_input_embedded = tf.nn.embedding_lookup(input_embedding, input_x)\n",
    "    # conv = tf.layers.conv1d(x_input_embedded, num_filters, kernel_size, name='conv')\n",
    "    # # global max pooling layer\n",
    "    # pooling = tf.reduce_max(conv, reduction_indices=[1])\n",
    "    fw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "    fw_cell = tf.nn.rnn_cell.DropoutWrapper(fw_cell, output_keep_prob=keep_prob)\n",
    "    bw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "    bw_cell = tf.nn.rnn_cell.DropoutWrapper(bw_cell, output_keep_prob=keep_prob)\n",
    "    (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=fw_cell, cell_bw=bw_cell, inputs=x_input_embedded, dtype=tf.float32\n",
    "    )\n",
    "    shape = [tf.shape(output_fw)[0], 1, tf.shape(output_fw)[2]]\n",
    "    c_left = tf.concat([tf.zeros(shape), output_fw[:, :-1]], axis=1)\n",
    "    c_right = tf.concat([output_bw[:, 1:], tf.zeros(shape)], axis=1)\n",
    "    x = tf.concat([c_left, x_input_embedded, c_right], axis=2)\n",
    "    embedding_size = 2 * hidden_dim + embedding_dim\n",
    "    W2 = tf.Variable(tf.random_uniform([embedding_size, text_hidden_size], -1.0, 1.0))\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[text_hidden_size]))\n",
    "    y2 = tf.tanh(tf.einsum('aij, jk->aik', x, W2) + b2)\n",
    "    y3 = tf.reduce_max(y2, axis=1)\n",
    "    W4 = tf.get_variable(\"W4\", shape=[text_hidden_size, numclass],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.constant(0.1, shape=[numclass]))\n",
    "with tf.name_scope(\"score\"):\n",
    "    # # 全连接层，后面接dropout以及relu激活\n",
    "    # fc = tf.layers.dense(pooling, hidden_dim, name='fc1')\n",
    "    # fc = tf.contrib.layers.dropout(fc, keep_prob)\n",
    "    # fc = tf.nn.relu(fc)\n",
    "    #\n",
    "    # # 分类器\n",
    "    # logits = tf.layers.dense(fc, numclass, name='fc2')\n",
    "    logits = tf.nn.xw_plus_b(y3, W4, b4)\n",
    "    y_pred_cls = tf.argmax(tf.nn.softmax(logits), 1, name='y_pred')  # 预测类别\n",
    "\n",
    "with tf.name_scope(\"optimize\"):\n",
    "    # 将label进行onehot转化\n",
    "    one_hot_labels = tf.one_hot(input_y, depth=numclass, dtype=tf.float32)\n",
    "    # 损失函数，交叉熵\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_labels)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # 优化器\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    # 准确率\n",
    "    correct_pred = tf.equal(tf.argmax(one_hot_labels, 1), y_pred_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='acc')\n",
    "\n",
    "with tf.name_scope(\"summary\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "best_score = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter(LOG_PATH, sess.graph)\n",
    "\n",
    "    # dataset.get_step() 获取数据的总迭代次数\n",
    "    for step in range(dataset.get_step()):\n",
    "        x_train, y_train = dataset.next_train_batch()\n",
    "        # x_val, y_val = dataset.next_validation_batch()\n",
    "\n",
    "        fetches = [loss, accuracy, train_op]\n",
    "        feed_dict = {input_x: x_train, input_y: y_train, keep_prob: 0.9}\n",
    "        loss_, accuracy_, _ = sess.run(fetches, feed_dict=feed_dict)\n",
    "\n",
    "        summary = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "        cur_step = str(step + 1) + \"/\" + str(dataset.get_step())\n",
    "        print('The Current step per total: {} | The Current loss: {} | The Current ACC: {}'.\n",
    "              format(cur_step, loss_, accuracy_))\n",
    "        if step % 100 == 0:\n",
    "            model.save_model(sess, MODEL_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出结果不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Current step per total: 6/20 | The Current loss: 0.5880126953125 | The Current ACC: 0.78125\n",
    "The Current step per total: 7/20 | The Current loss: 0.5793024897575378 | The Current ACC: 0.78125\n",
    "The Current step per total: 8/20 | The Current loss: 0.5130840539932251 | The Current ACC: 0.78125\n",
    "The Current step per total: 9/20 | The Current loss: 0.4589272141456604 | The Current ACC: 0.78125\n",
    "The Current step per total: 10/20 | The Current loss: 0.40918341279029846 | The Current ACC: 0.78125\n",
    "The Current step per total: 11/20 | The Current loss: 0.37503427267074585 | The Current ACC: 0.78125\n",
    "The Current step per total: 12/20 | The Current loss: 0.33043915033340454 | The Current ACC: 0.796875\n",
    "The Current step per total: 13/20 | The Current loss: 0.28246819972991943 | The Current ACC: 0.890625\n",
    "The Current step per total: 14/20 | The Current loss: 0.2591536045074463 | The Current ACC: 0.921875\n",
    "The Current step per total: 15/20 | The Current loss: 0.2163408398628235 | The Current ACC: 0.90625\n",
    "The Current step per total: 16/20 | The Current loss: 0.1775176227092743 | The Current ACC: 0.96875\n",
    "The Current step per total: 17/20 | The Current loss: 0.14954215288162231 | The Current ACC: 0.984375\n",
    "The Current step per total: 18/20 | The Current loss: 0.12818661332130432 | The Current ACC: 1.0\n",
    "The Current step per total: 19/20 | The Current loss: 0.1094832792878151 | The Current ACC: 1.0\n",
    "The Current step per total: 20/20 | The Current loss: 0.08871211111545563 | The Current ACC: 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
